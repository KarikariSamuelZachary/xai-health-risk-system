{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e962395",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) Summary & Strategic Insights\n",
    "\n",
    "## 1. Introduction\n",
    "This notebook consolidates findings from the comprehensive EDA performed on the **Heart Disease** and **Diabetes** datasets. The analysis pipeline included:\n",
    "1.  **Data Cleaning:** Handling missing values, duplicates and data typing.\n",
    "2.  **Exploratory Analysis:** Univariate (distributions) and Bivariate (relationships) analysis.\n",
    "3.  **Statistical Checks:** Correlation analysis and Feature Redundancy (VIF).\n",
    "4.  **Merging Feasibility:** Evaluating if datasets could be combined.\n",
    "\n",
    "The insights below serve as the foundation for the Machine Learning modeling phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efa533",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview & Data Quality\n",
    "\n",
    "### Diabetes Dataset\n",
    "- **Source:** Pima Indians Diabetes Database.\n",
    "- **Structure:** ~768 rows, 9 features.\n",
    "- **Key Actions:**\n",
    "    - Identified invalid zero values in `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, and `BMI`.\n",
    "    - **Imputation:** Replaced invalid zeros with `NaN` and imputed using the **median** to handle skewness.\n",
    "    - **Data Types** Converted a categorical variable \"Outcome\"\n",
    "    - **Target:** `Outcome` (Binary: 0/1).\n",
    "\n",
    "### Heart Disease Dataset\n",
    "- **Source:** Cleveland Heart Disease Database.\n",
    "- **Structure:** ~303 rows, 14 features.\n",
    "- **Key Actions:**\n",
    "    - **Duplicates:** Identified and removed duplicate records to prevent data leakage.\n",
    "    - **Data Types:** Converted categorical variables (e.g., `sex`, `cp`, `thal`, `fbs`, `exang`, `restecg`, `slope`, `ca`) to proper category types for efficiency.\n",
    "    - **Target:** `target` (Binary: Presence/Absence of heart disease)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c48f82",
   "metadata": {},
   "source": [
    "## 3. Key EDA Findings\n",
    "\n",
    "### Distributions & Outliers\n",
    "- **Skewness:** Several features in the Diabetes dataset (e.g., `Insulin`, `DiabetesPedigreeFunction`) showed right-skewed distributions.\n",
    "- **Outliers:** Detected using the **IQR method**. Significant outliers were observed in `Insulin` and `SkinThickness`.\n",
    "    - *Decision:* Robust models (like Tree-based) or scaling/transformation will be needed for distance-based algorithms.\n",
    "\n",
    "### Feature Relationships\n",
    "- **Correlations:**\n",
    "    - **Diabetes:** Expected correlations observed (e.g., `Glucose` vs `Outcome`, `Age` vs `Pregnancies`).\n",
    "    - **Heart Disease:** Strong associations found between `cp` (chest pain), `thalach` (max heart rate), and the target.\n",
    "- **Multicollinearity:** Variance Inflation Factor (VIF) analysis was conducted for both datasets. It revealed that several features (notably Glucose, BloodPressure and BMI for the Diabetes datset) and (Age, trestsbps, thal and thalach for heart_disease dataset) have high VIF values, indicating strong multicollinerarity.\n",
    "    -**Implication** I must consider dimensionality reduction(removing or combining correlated features) before I train the logistic regresion model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97813e3b",
   "metadata": {},
   "source": [
    "## 4. Data Merging Feasibility\n",
    "**Conclusion:** The datasets **cannot be merged**.\n",
    "- **Reasoning:** There is no unique, reliable common identifier (Primary Key) between the two datasets.\n",
    "- **Implication:** I must build **two separate ML pipelines**â€”one for Heart Disease Risk and one for Diabetes Risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810d9e24",
   "metadata": {},
   "source": [
    "## 5. Strategic Recommendations for Machine Learning\n",
    "\n",
    "### Model Selection\n",
    "1.  **Baseline Model:** **Logistic Regression**\n",
    "    - *Why:* Provides a solid baseline and coefficients are directly interpretable (log-odds). Good for identifying linear risk factors.\n",
    "2.  **Challenger Model:** **Random Forest** or **XGBoost**\n",
    "    - *Why:* Handles non-linear relationships, robust to outliers (which I found), and manages feature interactions automatically.\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Primary:** **ROC-AUC** (Area Under the Receiver Operating Characteristic Curve).\n",
    "    - *Reason:* More robust than accuracy, especially if class imbalance exists in the future.\n",
    "- **Secondary:** **Recall (Sensitivity)**.\n",
    "    - *Reason:* In health risk, false negatives (missing a high-risk patient) are more costly than false positives.\n",
    "\n",
    "### Explainability (XAI)\n",
    "- Since \"black-box\" models like XGBoost may perform better, I **must** implement **SHAP (SHapley Additive exPlanations)**.\n",
    "- This will allow my model to answer: *\"Why is this specific person's risk score 0.73?\"* by showing the contribution of each feature (e.g., +0.2 from High Glucose, +0.1 from Age)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
